{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Race Predictor: Modeling Check-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Members: Maitri Patel and Daniel Lichter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [Part 1. Introduction](#part-one)\n",
    "* [Part 2. Feature Selection](#part-two)\n",
    "* [Part 3. Classification: Logistic Regression - Standardized Data](#part-three)\n",
    "* [Part 4. Classification: Logistic Regression - Normalized Data](#part-four)\n",
    "* [Part 5. Evaluating Our Model's Performance](#part-five)\n",
    "* [Part 6. Timeline](#part-six)\n",
    "* [Part 7. References](#part-seven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id=\"part-one\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the exploratory data portion of the final project, we left off with importing the data from the racing API and the Formula 1 website, and merging all of the data into one csv file. This file contains all of the data that we will need to complete our models for the F1 Race Predictor. In this model check-in, our goal is to start off creating the models for our predictor. We plan to try to create a classification and regression model but depending on time we may just try and perfect the classification model. At the end of this check-in, we hope to have a better understanding of our models, which can help us improve our performance performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid annoying warnings i'm going to ignore them using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exploratory data portion of this project, we saved the data in a csv file. To use that data, let's import the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>driver</th>\n",
       "      <th>grid</th>\n",
       "      <th>podium</th>\n",
       "      <th>...</th>\n",
       "      <th>constructor_minardi</th>\n",
       "      <th>constructor_prost</th>\n",
       "      <th>constructor_red_bull</th>\n",
       "      <th>constructor_renault</th>\n",
       "      <th>constructor_sauber</th>\n",
       "      <th>constructor_team_lotus</th>\n",
       "      <th>constructor_toro_rosso</th>\n",
       "      <th>constructor_toyota</th>\n",
       "      <th>constructor_tyrrell</th>\n",
       "      <th>constructor_williams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>keke_rosberg</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>prost</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tambay</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>piquet</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1983</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>warwick</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14267</th>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>giovinazzi</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14268</th>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>raikkonen</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14269</th>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>russell</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14270</th>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>kubica</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14271</th>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>bottas</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14272 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  round  weather_warm  weather_cold  weather_dry  weather_wet  \\\n",
       "0        1983      1         False         False         True        False   \n",
       "1        1983      1         False         False         True        False   \n",
       "2        1983      1         False         False         True        False   \n",
       "3        1983      1         False         False         True        False   \n",
       "4        1983      1         False         False         True        False   \n",
       "...       ...    ...           ...           ...          ...          ...   \n",
       "14267    2019     21          True         False        False        False   \n",
       "14268    2019     21          True         False        False        False   \n",
       "14269    2019     21          True         False        False        False   \n",
       "14270    2019     21          True         False        False        False   \n",
       "14271    2019     21          True         False        False        False   \n",
       "\n",
       "       weather_cloudy        driver  grid  podium  ...  constructor_minardi  \\\n",
       "0               False  keke_rosberg     1      15  ...                    0   \n",
       "1               False         prost     2       6  ...                    0   \n",
       "2               False        tambay     3       4  ...                    0   \n",
       "3               False        piquet     4       1  ...                    0   \n",
       "4               False       warwick     5       7  ...                    0   \n",
       "...               ...           ...   ...     ...  ...                  ...   \n",
       "14267           False    giovinazzi    16      16  ...                    0   \n",
       "14268           False     raikkonen    17      13  ...                    0   \n",
       "14269           False       russell    18      17  ...                    0   \n",
       "14270           False        kubica    19      19  ...                    0   \n",
       "14271           False        bottas    20       4  ...                    0   \n",
       "\n",
       "       constructor_prost  constructor_red_bull  constructor_renault  \\\n",
       "0                      0                     0                    0   \n",
       "1                      0                     0                    1   \n",
       "2                      0                     0                    0   \n",
       "3                      0                     0                    0   \n",
       "4                      0                     0                    0   \n",
       "...                  ...                   ...                  ...   \n",
       "14267                  0                     0                    0   \n",
       "14268                  0                     0                    0   \n",
       "14269                  0                     0                    0   \n",
       "14270                  0                     0                    0   \n",
       "14271                  0                     0                    0   \n",
       "\n",
       "       constructor_sauber  constructor_team_lotus  constructor_toro_rosso  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "...                   ...                     ...                     ...   \n",
       "14267                   0                       0                       0   \n",
       "14268                   0                       0                       0   \n",
       "14269                   0                       0                       0   \n",
       "14270                   0                       0                       0   \n",
       "14271                   0                       0                       0   \n",
       "\n",
       "       constructor_toyota  constructor_tyrrell  constructor_williams  \n",
       "0                       0                    0                     1  \n",
       "1                       0                    0                     0  \n",
       "2                       0                    0                     0  \n",
       "3                       0                    0                     0  \n",
       "4                       0                    0                     0  \n",
       "...                   ...                  ...                   ...  \n",
       "14267                   0                    0                     0  \n",
       "14268                   0                    0                     0  \n",
       "14269                   0                    0                     1  \n",
       "14270                   0                    0                     1  \n",
       "14271                   0                    0                     0  \n",
       "\n",
       "[14272 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "racing_df = pd.read_csv('f1_data.csv')\n",
    "racing_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the columns in our DataFrame so we can determine what we want to use for our feature and target columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'round', 'weather_warm', 'weather_cold', 'weather_dry',\n",
       "       'weather_wet', 'weather_cloudy', 'driver', 'grid', 'podium',\n",
       "       'driver_points', 'driver_wins', 'driver_standings_pos',\n",
       "       'constructor_points', 'constructor_wins', 'constructor_standings_pos',\n",
       "       'qualifying_time', 'driver_age', 'circuit_id_BAK',\n",
       "       'circuit_id_adelaide', 'circuit_id_albert_park', 'circuit_id_americas',\n",
       "       'circuit_id_bahrain', 'circuit_id_brands_hatch', 'circuit_id_catalunya',\n",
       "       'circuit_id_detroit', 'circuit_id_estoril', 'circuit_id_galvez',\n",
       "       'circuit_id_hockenheimring', 'circuit_id_hungaroring',\n",
       "       'circuit_id_imola', 'circuit_id_indianapolis', 'circuit_id_interlagos',\n",
       "       'circuit_id_istanbul', 'circuit_id_jacarepagua', 'circuit_id_jerez',\n",
       "       'circuit_id_kyalami', 'circuit_id_magny_cours', 'circuit_id_marina_bay',\n",
       "       'circuit_id_monaco', 'circuit_id_monza', 'circuit_id_nurburgring',\n",
       "       'circuit_id_osterreichring', 'circuit_id_phoenix',\n",
       "       'circuit_id_red_bull_ring', 'circuit_id_ricard', 'circuit_id_rodriguez',\n",
       "       'circuit_id_sepang', 'circuit_id_shanghai', 'circuit_id_silverstone',\n",
       "       'circuit_id_sochi', 'circuit_id_spa', 'circuit_id_suzuka',\n",
       "       'circuit_id_valencia', 'circuit_id_villeneuve', 'circuit_id_yas_marina',\n",
       "       'circuit_id_yeongam', 'circuit_id_zandvoort', 'nationality_American',\n",
       "       'nationality_Australian', 'nationality_Austrian', 'nationality_Belgian',\n",
       "       'nationality_Brazilian', 'nationality_British', 'nationality_Canadian',\n",
       "       'nationality_Dutch', 'nationality_Finnish', 'nationality_French',\n",
       "       'nationality_German', 'nationality_Italian', 'nationality_Japanese',\n",
       "       'nationality_Mexican', 'nationality_Russian', 'nationality_Spanish',\n",
       "       'nationality_Swedish', 'constructor_arrows', 'constructor_bar',\n",
       "       'constructor_benetton', 'constructor_brabham', 'constructor_ferrari',\n",
       "       'constructor_footwork', 'constructor_force_india', 'constructor_haas',\n",
       "       'constructor_jaguar', 'constructor_jordan', 'constructor_larrousse',\n",
       "       'constructor_ligier', 'constructor_lotus_f1', 'constructor_mclaren',\n",
       "       'constructor_mercedes', 'constructor_minardi', 'constructor_prost',\n",
       "       'constructor_red_bull', 'constructor_renault', 'constructor_sauber',\n",
       "       'constructor_team_lotus', 'constructor_toro_rosso',\n",
       "       'constructor_toyota', 'constructor_tyrrell', 'constructor_williams'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "racing_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem we are solving? Who are you solving it for? Has this changed since the previous milestone?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving a forecasting problem of who will win a specific race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to split data and test our data on 2018 and 2019 seasons. (Wanted to do 2020 but data didn't "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features do you still need to make? What transformations do you still need to perform on your input data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection <a id=\"part-two\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start any models, it will help to save our feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = racing_df.columns.drop(['driver','podium'])\n",
    "target_column = 'podium'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are focusing on a classification model first, we have to convert the target variable to 0 and 1 for either winning the race or not. We also need to split our data into test and train. Our test data will be the race outcomes from the 2018 and 2019 seasons. The target variable will be the podium column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our X test and training sets will include all of the columns except for driver name and final podium placing. The training set will include the races from 1983-2017, and the test set will include the races from 2018 and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_X_train = racing_df[(racing_df['season']<2018)][feature_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_X_test = racing_df[(racing_df['season']>=2018)][feature_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our X test and train set, we can standardize the data in each set. This will ensure that the standard deviation is 1 between all rows in a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>grid</th>\n",
       "      <th>driver_points</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>...</th>\n",
       "      <th>constructor_minardi</th>\n",
       "      <th>constructor_prost</th>\n",
       "      <th>constructor_red_bull</th>\n",
       "      <th>constructor_renault</th>\n",
       "      <th>constructor_sauber</th>\n",
       "      <th>constructor_team_lotus</th>\n",
       "      <th>constructor_toro_rosso</th>\n",
       "      <th>constructor_toyota</th>\n",
       "      <th>constructor_tyrrell</th>\n",
       "      <th>constructor_williams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "      <td>1.348400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.537136e-15</td>\n",
       "      <td>1.462820e-15</td>\n",
       "      <td>-1.903221e-15</td>\n",
       "      <td>5.941463e-15</td>\n",
       "      <td>7.469617e-15</td>\n",
       "      <td>4.175300e-15</td>\n",
       "      <td>1.297629e-15</td>\n",
       "      <td>-9.859940e-16</td>\n",
       "      <td>1.319673e-14</td>\n",
       "      <td>2.216412e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.433481e-14</td>\n",
       "      <td>-5.776369e-15</td>\n",
       "      <td>-1.929814e-14</td>\n",
       "      <td>-7.110750e-15</td>\n",
       "      <td>-1.278357e-14</td>\n",
       "      <td>-1.501987e-14</td>\n",
       "      <td>1.853713e-14</td>\n",
       "      <td>5.897405e-15</td>\n",
       "      <td>-2.343055e-14</td>\n",
       "      <td>1.936476e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "      <td>1.000037e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.643837e+00</td>\n",
       "      <td>-1.612338e+00</td>\n",
       "      <td>-8.054898e-01</td>\n",
       "      <td>-1.561619e-01</td>\n",
       "      <td>-5.655885e-01</td>\n",
       "      <td>-3.409181e-01</td>\n",
       "      <td>-3.445659e-01</td>\n",
       "      <td>-1.611470e+00</td>\n",
       "      <td>-4.621364e-01</td>\n",
       "      <td>-3.097328e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.200932e-01</td>\n",
       "      <td>-1.109609e-01</td>\n",
       "      <td>-1.898298e-01</td>\n",
       "      <td>-1.988712e-01</td>\n",
       "      <td>-2.361079e-01</td>\n",
       "      <td>-1.663297e-01</td>\n",
       "      <td>-1.806203e-01</td>\n",
       "      <td>-1.421311e-01</td>\n",
       "      <td>-1.904579e-01</td>\n",
       "      <td>-3.109758e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.648670e-01</td>\n",
       "      <td>-8.195519e-01</td>\n",
       "      <td>-8.054898e-01</td>\n",
       "      <td>-1.561619e-01</td>\n",
       "      <td>-5.655885e-01</td>\n",
       "      <td>-3.409181e-01</td>\n",
       "      <td>-3.445659e-01</td>\n",
       "      <td>-8.732753e-01</td>\n",
       "      <td>-4.621364e-01</td>\n",
       "      <td>-3.097328e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.200932e-01</td>\n",
       "      <td>-1.109609e-01</td>\n",
       "      <td>-1.898298e-01</td>\n",
       "      <td>-1.988712e-01</td>\n",
       "      <td>-2.361079e-01</td>\n",
       "      <td>-1.663297e-01</td>\n",
       "      <td>-1.806203e-01</td>\n",
       "      <td>-1.421311e-01</td>\n",
       "      <td>-1.904579e-01</td>\n",
       "      <td>-3.109758e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.147456e-02</td>\n",
       "      <td>-2.676622e-02</td>\n",
       "      <td>-8.054898e-01</td>\n",
       "      <td>-1.561619e-01</td>\n",
       "      <td>-5.655885e-01</td>\n",
       "      <td>-3.409181e-01</td>\n",
       "      <td>-3.445659e-01</td>\n",
       "      <td>1.255873e-02</td>\n",
       "      <td>-3.830949e-01</td>\n",
       "      <td>-3.097328e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.200932e-01</td>\n",
       "      <td>-1.109609e-01</td>\n",
       "      <td>-1.898298e-01</td>\n",
       "      <td>-1.988712e-01</td>\n",
       "      <td>-2.361079e-01</td>\n",
       "      <td>-1.663297e-01</td>\n",
       "      <td>-1.806203e-01</td>\n",
       "      <td>-1.421311e-01</td>\n",
       "      <td>-1.904579e-01</td>\n",
       "      <td>-3.109758e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.878161e-01</td>\n",
       "      <td>7.660195e-01</td>\n",
       "      <td>1.241481e+00</td>\n",
       "      <td>-1.561619e-01</td>\n",
       "      <td>-5.655885e-01</td>\n",
       "      <td>-3.409181e-01</td>\n",
       "      <td>-3.445659e-01</td>\n",
       "      <td>7.507537e-01</td>\n",
       "      <td>-1.423458e-02</td>\n",
       "      <td>-3.097328e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.200932e-01</td>\n",
       "      <td>-1.109609e-01</td>\n",
       "      <td>-1.898298e-01</td>\n",
       "      <td>-1.988712e-01</td>\n",
       "      <td>-2.361079e-01</td>\n",
       "      <td>-1.663297e-01</td>\n",
       "      <td>-1.806203e-01</td>\n",
       "      <td>-1.421311e-01</td>\n",
       "      <td>-1.904579e-01</td>\n",
       "      <td>-3.109758e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.666786e+00</td>\n",
       "      <td>2.351591e+00</td>\n",
       "      <td>1.241481e+00</td>\n",
       "      <td>6.403611e+00</td>\n",
       "      <td>1.768070e+00</td>\n",
       "      <td>2.933256e+00</td>\n",
       "      <td>2.902203e+00</td>\n",
       "      <td>2.227144e+00</td>\n",
       "      <td>9.391703e+00</td>\n",
       "      <td>1.099674e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.543529e+00</td>\n",
       "      <td>9.012187e+00</td>\n",
       "      <td>5.267877e+00</td>\n",
       "      <td>5.028379e+00</td>\n",
       "      <td>4.235351e+00</td>\n",
       "      <td>6.012155e+00</td>\n",
       "      <td>5.536477e+00</td>\n",
       "      <td>7.035757e+00</td>\n",
       "      <td>5.250504e+00</td>\n",
       "      <td>3.215684e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             season         round  weather_warm  weather_cold   weather_dry  \\\n",
       "count  1.348400e+04  1.348400e+04  1.348400e+04  1.348400e+04  1.348400e+04   \n",
       "mean   3.537136e-15  1.462820e-15 -1.903221e-15  5.941463e-15  7.469617e-15   \n",
       "std    1.000037e+00  1.000037e+00  1.000037e+00  1.000037e+00  1.000037e+00   \n",
       "min   -1.643837e+00 -1.612338e+00 -8.054898e-01 -1.561619e-01 -5.655885e-01   \n",
       "25%   -8.648670e-01 -8.195519e-01 -8.054898e-01 -1.561619e-01 -5.655885e-01   \n",
       "50%    1.147456e-02 -2.676622e-02 -8.054898e-01 -1.561619e-01 -5.655885e-01   \n",
       "75%    8.878161e-01  7.660195e-01  1.241481e+00 -1.561619e-01 -5.655885e-01   \n",
       "max    1.666786e+00  2.351591e+00  1.241481e+00  6.403611e+00  1.768070e+00   \n",
       "\n",
       "        weather_wet  weather_cloudy          grid  driver_points  \\\n",
       "count  1.348400e+04    1.348400e+04  1.348400e+04   1.348400e+04   \n",
       "mean   4.175300e-15    1.297629e-15 -9.859940e-16   1.319673e-14   \n",
       "std    1.000037e+00    1.000037e+00  1.000037e+00   1.000037e+00   \n",
       "min   -3.409181e-01   -3.445659e-01 -1.611470e+00  -4.621364e-01   \n",
       "25%   -3.409181e-01   -3.445659e-01 -8.732753e-01  -4.621364e-01   \n",
       "50%   -3.409181e-01   -3.445659e-01  1.255873e-02  -3.830949e-01   \n",
       "75%   -3.409181e-01   -3.445659e-01  7.507537e-01  -1.423458e-02   \n",
       "max    2.933256e+00    2.902203e+00  2.227144e+00   9.391703e+00   \n",
       "\n",
       "        driver_wins  ...  constructor_minardi  constructor_prost  \\\n",
       "count  1.348400e+04  ...         1.348400e+04       1.348400e+04   \n",
       "mean   2.216412e-16  ...         1.433481e-14      -5.776369e-15   \n",
       "std    1.000037e+00  ...         1.000037e+00       1.000037e+00   \n",
       "min   -3.097328e-01  ...        -2.200932e-01      -1.109609e-01   \n",
       "25%   -3.097328e-01  ...        -2.200932e-01      -1.109609e-01   \n",
       "50%   -3.097328e-01  ...        -2.200932e-01      -1.109609e-01   \n",
       "75%   -3.097328e-01  ...        -2.200932e-01      -1.109609e-01   \n",
       "max    1.099674e+01  ...         4.543529e+00       9.012187e+00   \n",
       "\n",
       "       constructor_red_bull  constructor_renault  constructor_sauber  \\\n",
       "count          1.348400e+04         1.348400e+04        1.348400e+04   \n",
       "mean          -1.929814e-14        -7.110750e-15       -1.278357e-14   \n",
       "std            1.000037e+00         1.000037e+00        1.000037e+00   \n",
       "min           -1.898298e-01        -1.988712e-01       -2.361079e-01   \n",
       "25%           -1.898298e-01        -1.988712e-01       -2.361079e-01   \n",
       "50%           -1.898298e-01        -1.988712e-01       -2.361079e-01   \n",
       "75%           -1.898298e-01        -1.988712e-01       -2.361079e-01   \n",
       "max            5.267877e+00         5.028379e+00        4.235351e+00   \n",
       "\n",
       "       constructor_team_lotus  constructor_toro_rosso  constructor_toyota  \\\n",
       "count            1.348400e+04            1.348400e+04        1.348400e+04   \n",
       "mean            -1.501987e-14            1.853713e-14        5.897405e-15   \n",
       "std              1.000037e+00            1.000037e+00        1.000037e+00   \n",
       "min             -1.663297e-01           -1.806203e-01       -1.421311e-01   \n",
       "25%             -1.663297e-01           -1.806203e-01       -1.421311e-01   \n",
       "50%             -1.663297e-01           -1.806203e-01       -1.421311e-01   \n",
       "75%             -1.663297e-01           -1.806203e-01       -1.421311e-01   \n",
       "max              6.012155e+00            5.536477e+00        7.035757e+00   \n",
       "\n",
       "       constructor_tyrrell  constructor_williams  \n",
       "count         1.348400e+04          1.348400e+04  \n",
       "mean         -2.343055e-14          1.936476e-15  \n",
       "std           1.000037e+00          1.000037e+00  \n",
       "min          -1.904579e-01         -3.109758e-01  \n",
       "25%          -1.904579e-01         -3.109758e-01  \n",
       "50%          -1.904579e-01         -3.109758e-01  \n",
       "75%          -1.904579e-01         -3.109758e-01  \n",
       "max           5.250504e+00          3.215684e+00  \n",
       "\n",
       "[8 rows x 98 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(class_X_train[feature_columns])\n",
    "class_X_train[feature_columns] = scaler.transform(class_X_train[feature_columns])\n",
    "class_X_train[feature_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>grid</th>\n",
       "      <th>driver_points</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>...</th>\n",
       "      <th>constructor_minardi</th>\n",
       "      <th>constructor_prost</th>\n",
       "      <th>constructor_red_bull</th>\n",
       "      <th>constructor_renault</th>\n",
       "      <th>constructor_sauber</th>\n",
       "      <th>constructor_team_lotus</th>\n",
       "      <th>constructor_toro_rosso</th>\n",
       "      <th>constructor_toyota</th>\n",
       "      <th>constructor_tyrrell</th>\n",
       "      <th>constructor_williams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>788.0</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>788.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>788.0</td>\n",
       "      <td>7.880000e+02</td>\n",
       "      <td>788.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>7.880000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.249767e-13</td>\n",
       "      <td>-1.036396e-15</td>\n",
       "      <td>1.506409e-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.437584e-15</td>\n",
       "      <td>2.687501e-16</td>\n",
       "      <td>7.430604e-16</td>\n",
       "      <td>6.340106e-17</td>\n",
       "      <td>-3.116514e-16</td>\n",
       "      <td>-1.752687e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.606816e-17</td>\n",
       "      <td>2.521953e-17</td>\n",
       "      <td>1.117549e-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.648428e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.608978e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000635e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000635e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.949367e-01</td>\n",
       "      <td>-1.641034e+00</td>\n",
       "      <td>-6.047186e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.571859e-01</td>\n",
       "      <td>-1.613743e-01</td>\n",
       "      <td>-5.597619e-01</td>\n",
       "      <td>-1.619419e+00</td>\n",
       "      <td>-6.858876e-01</td>\n",
       "      <td>-3.376188e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.219339e-01</td>\n",
       "      <td>-3.338031e-01</td>\n",
       "      <td>-2.372768e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.267133e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.267133e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.949367e-01</td>\n",
       "      <td>-8.207250e-01</td>\n",
       "      <td>-6.047186e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.571859e-01</td>\n",
       "      <td>-1.613743e-01</td>\n",
       "      <td>-5.597619e-01</td>\n",
       "      <td>-9.047161e-01</td>\n",
       "      <td>-6.329643e-01</td>\n",
       "      <td>-3.376188e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.219339e-01</td>\n",
       "      <td>-3.338031e-01</td>\n",
       "      <td>-2.372768e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.267133e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.267133e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-9.949367e-01</td>\n",
       "      <td>-4.164003e-04</td>\n",
       "      <td>-6.047186e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.571859e-01</td>\n",
       "      <td>-1.613743e-01</td>\n",
       "      <td>-5.597619e-01</td>\n",
       "      <td>-1.133729e-02</td>\n",
       "      <td>-4.146556e-01</td>\n",
       "      <td>-3.376188e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.219339e-01</td>\n",
       "      <td>-3.338031e-01</td>\n",
       "      <td>-2.372768e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.267133e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.267133e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.005089e+00</td>\n",
       "      <td>8.198922e-01</td>\n",
       "      <td>1.653662e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.571859e-01</td>\n",
       "      <td>-1.613743e-01</td>\n",
       "      <td>-5.597619e-01</td>\n",
       "      <td>8.820415e-01</td>\n",
       "      <td>4.180808e-02</td>\n",
       "      <td>-3.376188e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.219339e-01</td>\n",
       "      <td>-3.338031e-01</td>\n",
       "      <td>-2.372768e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.267133e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.267133e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.005089e+00</td>\n",
       "      <td>1.640201e+00</td>\n",
       "      <td>1.653662e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.361893e+00</td>\n",
       "      <td>6.196773e+00</td>\n",
       "      <td>1.786474e+00</td>\n",
       "      <td>1.775420e+00</td>\n",
       "      <td>4.434444e+00</td>\n",
       "      <td>6.135462e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.106227e+00</td>\n",
       "      <td>2.995778e+00</td>\n",
       "      <td>4.214487e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.060788e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.060788e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             season         round  weather_warm  weather_cold   weather_dry  \\\n",
       "count  7.880000e+02  7.880000e+02  7.880000e+02         788.0  7.880000e+02   \n",
       "mean   1.249767e-13 -1.036396e-15  1.506409e-15           0.0 -1.437584e-15   \n",
       "std    1.000635e+00  1.000635e+00  1.000635e+00           0.0  1.000635e+00   \n",
       "min   -9.949367e-01 -1.641034e+00 -6.047186e-01           0.0 -1.571859e-01   \n",
       "25%   -9.949367e-01 -8.207250e-01 -6.047186e-01           0.0 -1.571859e-01   \n",
       "50%   -9.949367e-01 -4.164003e-04 -6.047186e-01           0.0 -1.571859e-01   \n",
       "75%    1.005089e+00  8.198922e-01  1.653662e+00           0.0 -1.571859e-01   \n",
       "max    1.005089e+00  1.640201e+00  1.653662e+00           0.0  6.361893e+00   \n",
       "\n",
       "        weather_wet  weather_cloudy          grid  driver_points  \\\n",
       "count  7.880000e+02    7.880000e+02  7.880000e+02   7.880000e+02   \n",
       "mean   2.687501e-16    7.430604e-16  6.340106e-17  -3.116514e-16   \n",
       "std    1.000635e+00    1.000635e+00  1.000635e+00   1.000635e+00   \n",
       "min   -1.613743e-01   -5.597619e-01 -1.619419e+00  -6.858876e-01   \n",
       "25%   -1.613743e-01   -5.597619e-01 -9.047161e-01  -6.329643e-01   \n",
       "50%   -1.613743e-01   -5.597619e-01 -1.133729e-02  -4.146556e-01   \n",
       "75%   -1.613743e-01   -5.597619e-01  8.820415e-01   4.180808e-02   \n",
       "max    6.196773e+00    1.786474e+00  1.775420e+00   4.434444e+00   \n",
       "\n",
       "        driver_wins  ...  constructor_minardi  constructor_prost  \\\n",
       "count  7.880000e+02  ...                788.0              788.0   \n",
       "mean  -1.752687e-16  ...                  0.0                0.0   \n",
       "std    1.000635e+00  ...                  0.0                0.0   \n",
       "min   -3.376188e-01  ...                  0.0                0.0   \n",
       "25%   -3.376188e-01  ...                  0.0                0.0   \n",
       "50%   -3.376188e-01  ...                  0.0                0.0   \n",
       "75%   -3.376188e-01  ...                  0.0                0.0   \n",
       "max    6.135462e+00  ...                  0.0                0.0   \n",
       "\n",
       "       constructor_red_bull  constructor_renault  constructor_sauber  \\\n",
       "count          7.880000e+02         7.880000e+02        7.880000e+02   \n",
       "mean          -3.606816e-17         2.521953e-17        1.117549e-15   \n",
       "std            1.000635e+00         1.000635e+00        1.000635e+00   \n",
       "min           -3.219339e-01        -3.338031e-01       -2.372768e-01   \n",
       "25%           -3.219339e-01        -3.338031e-01       -2.372768e-01   \n",
       "50%           -3.219339e-01        -3.338031e-01       -2.372768e-01   \n",
       "75%           -3.219339e-01        -3.338031e-01       -2.372768e-01   \n",
       "max            3.106227e+00         2.995778e+00        4.214487e+00   \n",
       "\n",
       "       constructor_team_lotus  constructor_toro_rosso  constructor_toyota  \\\n",
       "count                   788.0            7.880000e+02               788.0   \n",
       "mean                      0.0            1.648428e-16                 0.0   \n",
       "std                       0.0            1.000635e+00                 0.0   \n",
       "min                       0.0           -3.267133e-01                 0.0   \n",
       "25%                       0.0           -3.267133e-01                 0.0   \n",
       "50%                       0.0           -3.267133e-01                 0.0   \n",
       "75%                       0.0           -3.267133e-01                 0.0   \n",
       "max                       0.0            3.060788e+00                 0.0   \n",
       "\n",
       "       constructor_tyrrell  constructor_williams  \n",
       "count                788.0          7.880000e+02  \n",
       "mean                   0.0          1.608978e-16  \n",
       "std                    0.0          1.000635e+00  \n",
       "min                    0.0         -3.267133e-01  \n",
       "25%                    0.0         -3.267133e-01  \n",
       "50%                    0.0         -3.267133e-01  \n",
       "75%                    0.0         -3.267133e-01  \n",
       "max                    0.0          3.060788e+00  \n",
       "\n",
       "[8 rows x 98 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(class_X_test[feature_columns])\n",
    "class_X_test[feature_columns] = scaler.transform(class_X_test[feature_columns])\n",
    "class_X_test[feature_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Y test and training sets will only include the final podium position from the racing_df DataFrame. Since we are using classification models, if the podium position is 1 then it will keep its value. Any other podium position will be equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "podium\n",
       "0    746\n",
       "1     42\n",
       "Name: podium, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_Y_test = racing_df[(racing_df['season']>=2018)][target_column].map(lambda x: 1 if x==1 else 0)\n",
    "class_Y_test.groupby(class_Y_test).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test set has 2 years each with 21 races so the data above is correct.\n",
    "\n",
    "Now lets do the same to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "podium\n",
       "0    12882\n",
       "1      602\n",
       "Name: podium, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_Y_train = racing_df[(racing_df['season']<2018)][target_column].map(lambda x: 1 if x==1 else 0)\n",
    "class_Y_train.groupby(class_Y_train).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to confirm these numbers, we will look at the total amount of race winners across the full dataset and we will see that we have the correct amount of race winners. (42+602=644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(racing_df[racing_df['podium']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Logistic Regression - Standardized Data <a id=\"part-three\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model were going to create is a logistic regression using our standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=2020)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state = 2020, max_iter=1000)\n",
    "log_model.fit(class_X_train, class_Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the best hyperparameters for our model, so we will use GridSearchCV to find these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, random_state=2020, solver='newton-cg', tol=0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "log_search = GridSearchCV(log_model, {\n",
    "    'C' : [1,10,100,1000] , 'tol' :[.0001, .001, .01, .1] , 'max_iter' : [1,10,100,1000], 'solver' : ('newton-cg', 'lbfgs')\n",
    "})\n",
    "log_search.fit(class_X_train, class_Y_train)\n",
    "\n",
    "print(log_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have gotten the best parameters for our logistic regression, lets create the regression and see how well the model performs. Because we are trying to determine if the driver will win a race, we will use .predict_proba( ) for our predictions to see the probability of the prediction being 0 or being 1.  We will then take the person with the highest probability to be 1 as our predicted race winner. We tried to make predictions using the .predict( ) method but we only got 4 predicted winners despite dealing with 42 races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.80270351e-01, 4.19729649e-01],\n",
       "       [7.78088863e-01, 2.21911137e-01],\n",
       "       [8.07712985e-01, 1.92287015e-01],\n",
       "       ...,\n",
       "       [9.99997303e-01, 2.69693769e-06],\n",
       "       [9.99998440e-01, 1.56038433e-06],\n",
       "       [9.99982884e-01, 1.71163830e-05]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression using the best parameters found previously\n",
    "log_model = LogisticRegression(C=1, random_state=2020, solver='newton-cg', tol=0.01)\n",
    "#Fitting the model\n",
    "log_model.fit(class_X_train, class_Y_train)\n",
    "#Getting the probability of 0's and 1's in our model\n",
    "log_predictions = log_model.predict_proba(class_X_test)\n",
    "log_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predicted probabilities, we will have to find the highest probability of a one from our predictions for each race and use those to determine our predicted winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season  round\n",
       "2018    1        0.419730\n",
       "        2        0.471239\n",
       "        3        0.505170\n",
       "        4        0.496754\n",
       "        5        0.415030\n",
       "        6        0.307939\n",
       "        7        0.414321\n",
       "        8        0.460758\n",
       "        9        0.353493\n",
       "        10       0.401151\n",
       "        11       0.487565\n",
       "        12       0.436157\n",
       "        13       0.466223\n",
       "        14       0.319912\n",
       "        15       0.460823\n",
       "        16       0.373160\n",
       "        17       0.486389\n",
       "        18       0.523805\n",
       "        19       0.268371\n",
       "        20       0.510977\n",
       "        21       0.522731\n",
       "2019    1        0.326977\n",
       "        2        0.209957\n",
       "        3        0.257366\n",
       "        4        0.279984\n",
       "        5        0.228076\n",
       "        6        0.410896\n",
       "        7        0.275407\n",
       "        8        0.444584\n",
       "        9        0.153882\n",
       "        10       0.311073\n",
       "        11       0.454226\n",
       "        12       0.245363\n",
       "        13       0.218185\n",
       "        14       0.341854\n",
       "        15       0.300375\n",
       "        16       0.319334\n",
       "        17       0.223552\n",
       "        18       0.227002\n",
       "        19       0.232512\n",
       "        20       0.239611\n",
       "        21       0.464444\n",
       "Name: proba_1, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating test_df to hold our predicted probabilites.\n",
    "test_df =  pd.DataFrame(log_model.predict_proba(class_X_test), columns = ['proba_0', 'proba_1'])\n",
    "#Adding the season and round of the data so we can group the data by season and round\n",
    "test_df[['season','round']] = racing_df[racing_df['season']>=2018][['season','round']].reset_index(drop = True)\n",
    "#Finding the highest probability of race winner for each race. Want to use this to make \n",
    "#the predictons 1 for these and 0 for the rest\n",
    "test_df.groupby(('season','round'))['proba_1'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred\n",
       "0.0    746\n",
       "1.0     42\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the max values and inserting it into test_df\n",
    "max_predict = test_df.groupby(('season', 'round'))['proba_1'].transform('max')\n",
    "test_df['pred'] = max_predict\n",
    "\n",
    "#makes all max predictions equal to 1\n",
    "test_df['pred'].loc[test_df['proba_1'] != test_df['pred']] = 0\n",
    "test_df['pred'].loc[test_df['proba_1'] == test_df['pred']] = 1\n",
    "\n",
    "#Looking to see if we have the correct amount of predicted 0's and 1's.\n",
    "test_df.groupby('pred')['pred'].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 42 predicted winners and 746 predicted non-winners. Lets compare that to the class_Y_test data that we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "podium\n",
       "0    746\n",
       "1     42\n",
       "Name: podium, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_Y_test.groupby(class_Y_test).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have the correct amount of predicted winners so the work on this model is complete for now. We will look at the performance and if we can improve it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.939\n",
      "Precision:  0.429\n",
      "Recall:  0.429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print('Accuracy: ', round(accuracy_score(test_df['pred'], class_Y_test), 3))\n",
    "print('Precision: ', round(precision_score(test_df['pred'], class_Y_test), 3))\n",
    "print('Recall: ', round(recall_score(test_df['pred'], class_Y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Logistic Regression - Normalized Data <a id=\"part-four\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I want to use the same code but normalize the data instead of standardizing it. From here, I plan to see which method produces better performance from the model. Normalizing the data scales our data from 0 to 1 instead of ensuring that the standard deviation is 1. We will start by doing this to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>grid</th>\n",
       "      <th>driver_points</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>...</th>\n",
       "      <th>constructor_minardi</th>\n",
       "      <th>constructor_prost</th>\n",
       "      <th>constructor_red_bull</th>\n",
       "      <th>constructor_renault</th>\n",
       "      <th>constructor_sauber</th>\n",
       "      <th>constructor_team_lotus</th>\n",
       "      <th>constructor_toro_rosso</th>\n",
       "      <th>constructor_toyota</th>\n",
       "      <th>constructor_tyrrell</th>\n",
       "      <th>constructor_williams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "      <td>13484.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.496534</td>\n",
       "      <td>0.406752</td>\n",
       "      <td>0.393503</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>0.242361</td>\n",
       "      <td>0.104123</td>\n",
       "      <td>0.106126</td>\n",
       "      <td>0.419805</td>\n",
       "      <td>0.046899</td>\n",
       "      <td>0.027394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046203</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.034782</td>\n",
       "      <td>0.038045</td>\n",
       "      <td>0.052803</td>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.019801</td>\n",
       "      <td>0.035004</td>\n",
       "      <td>0.088179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302069</td>\n",
       "      <td>0.252284</td>\n",
       "      <td>0.488545</td>\n",
       "      <td>0.152450</td>\n",
       "      <td>0.428528</td>\n",
       "      <td>0.305432</td>\n",
       "      <td>0.308010</td>\n",
       "      <td>0.260520</td>\n",
       "      <td>0.101487</td>\n",
       "      <td>0.088448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209932</td>\n",
       "      <td>0.109615</td>\n",
       "      <td>0.183234</td>\n",
       "      <td>0.191312</td>\n",
       "      <td>0.223649</td>\n",
       "      <td>0.161858</td>\n",
       "      <td>0.174920</td>\n",
       "      <td>0.139322</td>\n",
       "      <td>0.183798</td>\n",
       "      <td>0.283565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             season         round  weather_warm  weather_cold   weather_dry  \\\n",
       "count  13484.000000  13484.000000  13484.000000  13484.000000  13484.000000   \n",
       "mean       0.496534      0.406752      0.393503      0.023806      0.242361   \n",
       "std        0.302069      0.252284      0.488545      0.152450      0.428528   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.235294      0.200000      0.000000      0.000000      0.000000   \n",
       "50%        0.500000      0.400000      0.000000      0.000000      0.000000   \n",
       "75%        0.764706      0.600000      1.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        weather_wet  weather_cloudy          grid  driver_points  \\\n",
       "count  13484.000000    13484.000000  13484.000000   13484.000000   \n",
       "mean       0.104123        0.106126      0.419805       0.046899   \n",
       "std        0.305432        0.308010      0.260520       0.101487   \n",
       "min        0.000000        0.000000      0.000000       0.000000   \n",
       "25%        0.000000        0.000000      0.192308       0.000000   \n",
       "50%        0.000000        0.000000      0.423077       0.008021   \n",
       "75%        0.000000        0.000000      0.615385       0.045455   \n",
       "max        1.000000        1.000000      1.000000       1.000000   \n",
       "\n",
       "        driver_wins  ...  constructor_minardi  constructor_prost  \\\n",
       "count  13484.000000  ...         13484.000000       13484.000000   \n",
       "mean       0.027394  ...             0.046203           0.012163   \n",
       "std        0.088448  ...             0.209932           0.109615   \n",
       "min        0.000000  ...             0.000000           0.000000   \n",
       "25%        0.000000  ...             0.000000           0.000000   \n",
       "50%        0.000000  ...             0.000000           0.000000   \n",
       "75%        0.000000  ...             0.000000           0.000000   \n",
       "max        1.000000  ...             1.000000           1.000000   \n",
       "\n",
       "       constructor_red_bull  constructor_renault  constructor_sauber  \\\n",
       "count          13484.000000         13484.000000        13484.000000   \n",
       "mean               0.034782             0.038045            0.052803   \n",
       "std                0.183234             0.191312            0.223649   \n",
       "min                0.000000             0.000000            0.000000   \n",
       "25%                0.000000             0.000000            0.000000   \n",
       "50%                0.000000             0.000000            0.000000   \n",
       "75%                0.000000             0.000000            0.000000   \n",
       "max                1.000000             1.000000            1.000000   \n",
       "\n",
       "       constructor_team_lotus  constructor_toro_rosso  constructor_toyota  \\\n",
       "count            13484.000000            13484.000000        13484.000000   \n",
       "mean                 0.026921                0.031593            0.019801   \n",
       "std                  0.161858                0.174920            0.139322   \n",
       "min                  0.000000                0.000000            0.000000   \n",
       "25%                  0.000000                0.000000            0.000000   \n",
       "50%                  0.000000                0.000000            0.000000   \n",
       "75%                  0.000000                0.000000            0.000000   \n",
       "max                  1.000000                1.000000            1.000000   \n",
       "\n",
       "       constructor_tyrrell  constructor_williams  \n",
       "count         13484.000000          13484.000000  \n",
       "mean              0.035004              0.088179  \n",
       "std               0.183798              0.283565  \n",
       "min               0.000000              0.000000  \n",
       "25%               0.000000              0.000000  \n",
       "50%               0.000000              0.000000  \n",
       "75%               0.000000              0.000000  \n",
       "max               1.000000              1.000000  \n",
       "\n",
       "[8 rows x 98 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_X_train_norm = racing_df[(racing_df['season']<2018)][feature_columns]\n",
    "#one method of normalizing data - can also use MinMaxScaler()\n",
    "class_X_train_norm.loc[:, feature_columns] = ((class_X_train_norm[feature_columns] - \n",
    "                        class_X_train_norm[feature_columns].min()) / (class_X_train_norm[feature_columns].max() \n",
    "                                                                      - class_X_train_norm[feature_columns].min()))\n",
    "#fill in all NaN values with zero\n",
    "class_X_train_norm = class_X_train_norm.fillna(0)\n",
    "class_X_train_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>grid</th>\n",
       "      <th>driver_points</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>...</th>\n",
       "      <th>constructor_minardi</th>\n",
       "      <th>constructor_prost</th>\n",
       "      <th>constructor_red_bull</th>\n",
       "      <th>constructor_renault</th>\n",
       "      <th>constructor_sauber</th>\n",
       "      <th>constructor_team_lotus</th>\n",
       "      <th>constructor_toro_rosso</th>\n",
       "      <th>constructor_toyota</th>\n",
       "      <th>constructor_tyrrell</th>\n",
       "      <th>constructor_williams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.0</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>788.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.0</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>788.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>788.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.500127</td>\n",
       "      <td>0.267766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.238579</td>\n",
       "      <td>0.477024</td>\n",
       "      <td>0.133954</td>\n",
       "      <td>0.052157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093909</td>\n",
       "      <td>0.100254</td>\n",
       "      <td>0.053299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500311</td>\n",
       "      <td>0.304957</td>\n",
       "      <td>0.443076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153493</td>\n",
       "      <td>0.157378</td>\n",
       "      <td>0.426485</td>\n",
       "      <td>0.294752</td>\n",
       "      <td>0.195424</td>\n",
       "      <td>0.154584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291887</td>\n",
       "      <td>0.300529</td>\n",
       "      <td>0.224773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.010336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.052972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.142119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           season       round  weather_warm  weather_cold  weather_dry  \\\n",
       "count  788.000000  788.000000    788.000000         788.0   788.000000   \n",
       "mean     0.497462    0.500127      0.267766           0.0     0.024112   \n",
       "std      0.500311    0.304957      0.443076           0.0     0.153493   \n",
       "min      0.000000    0.000000      0.000000           0.0     0.000000   \n",
       "25%      0.000000    0.250000      0.000000           0.0     0.000000   \n",
       "50%      0.000000    0.500000      0.000000           0.0     0.000000   \n",
       "75%      1.000000    0.750000      1.000000           0.0     0.000000   \n",
       "max      1.000000    1.000000      1.000000           0.0     1.000000   \n",
       "\n",
       "       weather_wet  weather_cloudy        grid  driver_points  driver_wins  \\\n",
       "count   788.000000      788.000000  788.000000     788.000000   788.000000   \n",
       "mean      0.025381        0.238579    0.477024       0.133954     0.052157   \n",
       "std       0.157378        0.426485    0.294752       0.195424     0.154584   \n",
       "min       0.000000        0.000000    0.000000       0.000000     0.000000   \n",
       "25%       0.000000        0.000000    0.210526       0.010336     0.000000   \n",
       "50%       0.000000        0.000000    0.473684       0.052972     0.000000   \n",
       "75%       0.000000        0.000000    0.736842       0.142119     0.000000   \n",
       "max       1.000000        1.000000    1.000000       1.000000     1.000000   \n",
       "\n",
       "       ...  constructor_minardi  constructor_prost  constructor_red_bull  \\\n",
       "count  ...                788.0              788.0            788.000000   \n",
       "mean   ...                  0.0                0.0              0.093909   \n",
       "std    ...                  0.0                0.0              0.291887   \n",
       "min    ...                  0.0                0.0              0.000000   \n",
       "25%    ...                  0.0                0.0              0.000000   \n",
       "50%    ...                  0.0                0.0              0.000000   \n",
       "75%    ...                  0.0                0.0              0.000000   \n",
       "max    ...                  0.0                0.0              1.000000   \n",
       "\n",
       "       constructor_renault  constructor_sauber  constructor_team_lotus  \\\n",
       "count           788.000000          788.000000                   788.0   \n",
       "mean              0.100254            0.053299                     0.0   \n",
       "std               0.300529            0.224773                     0.0   \n",
       "min               0.000000            0.000000                     0.0   \n",
       "25%               0.000000            0.000000                     0.0   \n",
       "50%               0.000000            0.000000                     0.0   \n",
       "75%               0.000000            0.000000                     0.0   \n",
       "max               1.000000            1.000000                     0.0   \n",
       "\n",
       "       constructor_toro_rosso  constructor_toyota  constructor_tyrrell  \\\n",
       "count              788.000000               788.0                788.0   \n",
       "mean                 0.096447                 0.0                  0.0   \n",
       "std                  0.295390                 0.0                  0.0   \n",
       "min                  0.000000                 0.0                  0.0   \n",
       "25%                  0.000000                 0.0                  0.0   \n",
       "50%                  0.000000                 0.0                  0.0   \n",
       "75%                  0.000000                 0.0                  0.0   \n",
       "max                  1.000000                 0.0                  0.0   \n",
       "\n",
       "       constructor_williams  \n",
       "count            788.000000  \n",
       "mean               0.096447  \n",
       "std                0.295390  \n",
       "min                0.000000  \n",
       "25%                0.000000  \n",
       "50%                0.000000  \n",
       "75%                0.000000  \n",
       "max                1.000000  \n",
       "\n",
       "[8 rows x 98 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_X_test_norm = racing_df[(racing_df['season']>=2018)][feature_columns]\n",
    "class_X_test_norm.loc[:, feature_columns] = ((class_X_test_norm[feature_columns] - \n",
    "                        class_X_test_norm[feature_columns].min()) / (class_X_test_norm[feature_columns].max() \n",
    "                                                                      - class_X_test_norm[feature_columns].min()))\n",
    "\n",
    "class_X_test_norm = class_X_test_norm.fillna(0)\n",
    "class_X_test_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to test out and see if normalizing the data will change the best hyperparameters for the model. And we will see that it changes the max_iter number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=1, random_state=2020, solver='newton-cg')\n"
     ]
    }
   ],
   "source": [
    "log_model_norm = LogisticRegression(random_state = 2020, max_iter=1000)\n",
    "log_model_norm.fit(class_X_train_norm, class_Y_train)\n",
    "log_search = GridSearchCV(log_model_norm, {\n",
    "    'C' : [1,10,100,1000] , 'tol' :[.0001, .001, .01, .1] , 'max_iter' : [1,10,100,1000], 'solver' : ('newton-cg', 'lbfgs')\n",
    "})\n",
    "log_search.fit(class_X_train_norm, class_Y_train)\n",
    "\n",
    "print(log_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets fit the model and get the predictions. These are the same steps as the previous model that we just looked at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.13901006e-01, 4.86098994e-01],\n",
       "       [7.30616038e-01, 2.69383962e-01],\n",
       "       [7.51431075e-01, 2.48568925e-01],\n",
       "       ...,\n",
       "       [9.99995191e-01, 4.80854454e-06],\n",
       "       [9.99996899e-01, 3.10127712e-06],\n",
       "       [9.99889528e-01, 1.10471977e-04]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_norm = LogisticRegression(C=1, random_state=2020, solver='newton-cg', max_iter = 1000)\n",
    "#Fitting the model\n",
    "log_model_norm.fit(class_X_train_norm, class_Y_train)\n",
    "#Getting the probability of 0's and 1's in our model\n",
    "log_predictions_norm = log_model_norm.predict_proba(class_X_test_norm)\n",
    "log_predictions_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season  round\n",
       "2018    1        0.486099\n",
       "        2        0.503185\n",
       "        3        0.569228\n",
       "        4        0.540407\n",
       "        5        0.498996\n",
       "        6        0.369077\n",
       "        7        0.451106\n",
       "        8        0.539316\n",
       "        9        0.491779\n",
       "        10       0.511232\n",
       "        11       0.580025\n",
       "        12       0.579768\n",
       "        13       0.622924\n",
       "        14       0.428853\n",
       "        15       0.613858\n",
       "        16       0.580215\n",
       "        17       0.700511\n",
       "        18       0.724666\n",
       "        19       0.524321\n",
       "        20       0.729863\n",
       "        21       0.736080\n",
       "2019    1        0.327853\n",
       "        2        0.177610\n",
       "        3        0.300015\n",
       "        4        0.338646\n",
       "        5        0.317026\n",
       "        6        0.507851\n",
       "        7        0.402299\n",
       "        8        0.575310\n",
       "        9        0.306677\n",
       "        10       0.488508\n",
       "        11       0.636925\n",
       "        12       0.393378\n",
       "        13       0.454697\n",
       "        14       0.554788\n",
       "        15       0.482511\n",
       "        16       0.527743\n",
       "        17       0.317611\n",
       "        18       0.451580\n",
       "        19       0.317381\n",
       "        20       0.496763\n",
       "        21       0.669384\n",
       "Name: proba_1, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating test_df to hold our predicted probabilites.\n",
    "test_df_norm =  pd.DataFrame(log_model_norm.predict_proba(class_X_test_norm), columns = ['proba_0', 'proba_1'])\n",
    "\n",
    "#Adding the season and round of the data so we can group the data by season and round\n",
    "test_df_norm[['season','round']] = racing_df[racing_df['season']>=2018][['season','round']].reset_index(drop = True)\n",
    "\n",
    "#Finding the highest probability of race winner for each race. Want to use this to make \n",
    "#the predictons 1 for these and 0 for the rest\n",
    "test_df_norm.groupby(('season','round'))['proba_1'].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred\n",
       "0.0    746\n",
       "1.0     42\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the max values and inserting it into test_df\n",
    "max_predict = test_df_norm.groupby(('season', 'round'))['proba_1'].transform('max')\n",
    "test_df_norm['pred'] = max_predict\n",
    "\n",
    "#makes all max predictions equal to 1\n",
    "test_df_norm['pred'].loc[test_df_norm['proba_1'] != test_df_norm['pred']] = 0\n",
    "test_df_norm['pred'].loc[test_df_norm['proba_1'] == test_df_norm['pred']] = 1\n",
    "\n",
    "#Looking to see if we have the correct amount of predicted 0's and 1's.\n",
    "test_df_norm.groupby('pred')['pred'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model created, we will see how normalized data impacts the performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.949\n",
      "Precision:  0.524\n",
      "Recall:  0.524\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', round(accuracy_score(test_df_norm['pred'], class_Y_test), 3))\n",
    "print('Precision: ', round(precision_score(test_df_norm['pred'], class_Y_test), 3))\n",
    "print('Recall: ', round(recall_score(test_df_norm['pred'], class_Y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these metrics we can see that the model is very accurate, but this is expected because we are predicting many 0's. The most telling metric to look at is the precision which shows us how precise our positive predictions are. From the precision scores for the standardized vs normalized data, we can see that normalizing the data gives us more precise predictions at about 52.4% . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions for later: \n",
    "- Is this overfitting the data? best_estimator says max_iter = 1 but i used max_iter = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on to the Neural Networks, let's take a look at the ROC curves for each of the models and see how well the models performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "log_scores = log_model.decision_function(class_X_test)\n",
    "fpr_log, tpr_log, _ = roc_curve(class_Y_test, log_scores, pos_label=True)\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('ROC - Logistic Regression: Standardized Data')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.plot(fpr_log,tpr_log)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "\n",
    "log_scores_norm = log_model_norm.decision_function(class_X_test_norm)\n",
    "fpr_log_norm, tpr_log_norm, _ = roc_curve(class_Y_test, log_scores_norm, pos_label=True)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('ROC - Logistic Regression: Normalized Data')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.plot(fpr_log_norm,tpr_log_norm)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Logistic Regression with standardized data: 0.9468594408272691\n",
      "AUC for Logistic Regression with normalized data: 0.9440188944210393\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC for Logistic Regression with standardized data:\", roc_auc_score(class_Y_test,log_scores))\n",
    "print(\"AUC for Logistic Regression with normalized data:\", roc_auc_score(class_Y_test,log_scores_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC shows that the model's accuracy is great, but we need to figure out a better way to measure its precision. For this, we will use a precision-recall curve. But, to help first understand our data lets create a confusion matrix and see if we can determine the true postives, true negatives, false positives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Standardized Data:\n",
      "True Positive: 18\n",
      "True Negative: 722\n",
      "False Positive: 24\n",
      "False Negative: 24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn_stand, fp_stand, fn_stand, tp_stand = confusion_matrix(class_Y_test, test_df['pred']).ravel()\n",
    "print(\"Logistic Regression - Standardized Data:\")\n",
    "print(f'True Positive: {tp_stand}\\nTrue Negative: {tn_stand}\\nFalse Positive: {fp_stand}\\nFalse Negative: {fn_stand}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Normalized Data:\n",
      "True Positive: 22\n",
      "True Negative: 726\n",
      "False Positive: 20\n",
      "False Negative: 20\n"
     ]
    }
   ],
   "source": [
    "tn_norm, fp_norm, fn_norm, tp_norm = confusion_matrix(class_Y_test, test_df_norm['pred']).ravel()\n",
    "print(\"Logistic Regression - Normalized Data:\")\n",
    "print(f'True Positive: {tp_norm}\\nTrue Negative: {tn_norm}\\nFalse Positive: {fp_norm}\\nFalse Negative: {fn_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the normalized data has accurate true prediction and, as a result, also has less false predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(class_Y_test, test_df['pred'])\n",
    "plt.plot(recall, precision)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=1000).fit(class_X_train_norm, class_Y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(class_X_test)\n",
    "\n",
    "#Creating test_df to hold our predicted probabilites.\n",
    "rfc_df =  pd.DataFrame(rfc.predict_log_proba(class_X_test_norm), columns = ['proba_0', 'proba_1'])\n",
    "\n",
    "#Adding the season and round of the data so we can group the data by season and round\n",
    "rfc_df[['season','round']] = racing_df[racing_df['season']>=2018][['season','round']].reset_index(drop = True)\n",
    "\n",
    "#Finding the highest probability of race winner for each race. Want to use this to make \n",
    "#the predictons 1 for these and 0 for the rest\n",
    "rfc_df.groupby(('season','round'))['proba_1'].max()\n",
    "#using the max values and inserting it into test_df\n",
    "max_predict = rfc_df.groupby(('season', 'round'))['proba_1'].transform('max')\n",
    "rfc_df['pred'] = max_predict\n",
    "\n",
    "#makes all max predictions equal to 1\n",
    "rfc_df['pred'].loc[rfc_df['proba_1'] != rfc_df['pred']] = 0\n",
    "rfc_df['pred'].loc[rfc_df['proba_1'] == rfc_df['pred']] = 1\n",
    "\n",
    "#Looking to see if we have the correct amount of predicted 0's and 1's.\n",
    "rfc_df.groupby('pred')['pred'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', round(accuracy_score(rfc_df['pred'], class_Y_test), 3))\n",
    "print('Precision: ', round(precision_score(rfc_df['pred'], class_Y_test), 3))\n",
    "print('Recall: ', round(recall_score(rfc_df['pred'], class_Y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try out a neural network model. For our first attempt, we will use the classic NN model that we've used in the past few homeworks. After we get this working, we can try to change to an RNN or LSTM or fine tune this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "nn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu, \n",
    "                          input_shape=(len(feature_columns),)), #input size of 64 with relu activation function\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.softmax), #input size of 32 with softmax activation function\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu), #input size of 32 with relu activation function\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid) #output size of 1 and we use a sigmoid as our last activation function\n",
    "])\n",
    "\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = nn_model.fit(class_X_train, class_Y_train, epochs=500, \n",
    "                    verbose=2, callbacks = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "nn_model_norm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu, \n",
    "                          input_shape=(len(feature_columns),)), #input size of 64 with relu activation function\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.softmax), #input size of 32 with softmax activation function\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu), #input size of 32 with relu activation function\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid) #output size of 1 and we use a sigmoid as our last activation function\n",
    "])\n",
    "\n",
    "nn_model_norm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_model_norm.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_norm = nn_model_norm.fit(class_X_train_norm, class_Y_train, epochs=500, \n",
    "                    verbose=2, callbacks = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_norm.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Training Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy'], loc='best')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_norm.history['accuracy'])\n",
    "plt.title('Training Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy'], loc='best')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_norm.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating test_df to hold our predicted probabilites.\n",
    "nn_df =  pd.DataFrame(nn_model.predict(class_X_test), columns = ['proba_1'])\n",
    "\n",
    "#Adding the season and round of the data so we can group the data by season and round\n",
    "nn_df[['season','round','podium','driver']] = racing_df[racing_df['season']>=2018][['season','round','podium','driver']].reset_index(drop = True)\n",
    "\n",
    "#Finding the highest probability of race winner for each race. Want to use this to make \n",
    "#the predictons 1 for these and 0 for the rest\n",
    "nn_df.groupby(('season','round'))['proba_1'].max()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#using the max values and inserting it into test_df\n",
    "max_predict = nn_df.groupby(('season', 'round'))['proba_1'].transform('max')\n",
    "nn_df['pred'] = max_predict\n",
    "#nn_df_norm\n",
    "#makes all max predictions equal to 1\n",
    "nn_df['pred'].loc[nn_df['proba_1'] != nn_df['pred']] = 0\n",
    "nn_df['pred'].loc[nn_df['proba_1'] == nn_df['pred']] = 1\n",
    "\n",
    "#Looking to see if we have the correct amount of predicted 0's and 1's.\n",
    "nn_df.groupby('pred')['pred'].count()\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', round(accuracy_score(nn_df['pred'], class_Y_test), 3))\n",
    "print('Precision: ', round(precision_score(nn_df['pred'], class_Y_test), 3))\n",
    "print('Recall: ', round(recall_score(nn_df['pred'], class_Y_test), 3))\n",
    "print('F1: ', round(f1_score(nn_df['pred'], class_Y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating test_df to hold our predicted probabilites.\n",
    "nn_df_norm =  pd.DataFrame(nn_model_norm.predict(class_X_test_norm), columns = ['proba_1'])\n",
    "\n",
    "#Adding the season and round of the data so we can group the data by season and round\n",
    "nn_df_norm[['season','round','grid','podium','driver']] = racing_df[racing_df['season']>=2018][['season','round','grid','podium','driver']].reset_index(drop = True)\n",
    "\n",
    "#Finding the highest probability of race winner for each race. Want to use this to make \n",
    "#the predictons 1 for these and 0 for the rest\n",
    "nn_df_norm.groupby(('season','round'))['proba_1'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the max values and inserting it into test_df\n",
    "max_predict = nn_df_norm.groupby(('season', 'round'))['proba_1'].transform('max')\n",
    "nn_df_norm['pred'] = max_predict\n",
    "#nn_df_norm\n",
    "#makes all max predictions equal to 1\n",
    "nn_df_norm['pred'].loc[nn_df_norm['proba_1'] != nn_df_norm['pred']] = 0\n",
    "nn_df_norm['pred'].loc[nn_df_norm['proba_1'] == nn_df_norm['pred']] = 1\n",
    "\n",
    "#Looking to see if we have the correct amount of predicted 0's and 1's.\n",
    "nn_df_norm.groupby('pred')['pred'].count()\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ', round(accuracy_score(nn_df_norm['pred'], class_Y_test), 3))\n",
    "print('Precision: ', round(precision_score(nn_df_norm['pred'], class_Y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(class_Y_test, nn_df['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_df_norm[(nn_df_norm['pred']==1)| (nn_df_norm['podium']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see that the normalized data results in more precise predictions. Yet, these predictions are less precise than the logistic regression. To try and improve this, we will try another form of neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does your model’s performance look so far, in terms of quantitative metrics, qualitative evaluation, and visualizations? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We may have to figure out some way to assess the performance of this model.\n",
    "- Need to figure out how to classify one race winner per race\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Scores (Maybe do a ROC curve also?) \n",
    "- Look at coefficients?\n",
    "\n",
    "Very possible that the scores get worse with more seasons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "x_sample = class_X_test_norm.sample(100) #gives 20 rows of X_test\n",
    "nn_explainer = shap.KernelExplainer(nn_model_norm.predict,x_sample) \n",
    "nn_shap_values = nn_explainer.shap_values(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(nn_shap_values, x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(nn_explainer.expected_value,nn_shap_values[0][10], x_sample.iloc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please also include a rough project timeline, dividing up the work among your group members and demonstrating how you will complete both the analysis and the presentation by May 10th. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = class_X_train.shape[0], class_X_train.shape[1], class_Y_train.shape[0]"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
